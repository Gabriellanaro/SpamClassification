{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d425d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteopiccagnoni/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.3.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Load data ---\n",
    "df = pd.read_csv(\"lda_df.csv\")\n",
    "\n",
    "with open(\"lda_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "X_array = np.load(\"BoW_X_Array.npz\")[\"arr_0\"]\n",
    "X_tensor = torch.tensor(X_array, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95735e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set model parameters ---\n",
    "K = 15  # number of topics (can change)\n",
    "num_docs, vocab_size = X_tensor.shape\n",
    "\n",
    "\n",
    "# --- Define Pyro LDA model ---\n",
    "def lda_model(data):\n",
    "    with pyro.plate(\"topics\", K):\n",
    "        topic_words = pyro.sample(\"topic_words\", dist.Dirichlet(torch.ones(vocab_size)))\n",
    "\n",
    "    with pyro.plate(\"documents\", num_docs):\n",
    "        doc_topics = pyro.sample(\"doc_topics\", dist.Dirichlet(torch.ones(K)))\n",
    "\n",
    "        word_dists = torch.matmul(doc_topics, topic_words)\n",
    "        word_dists = word_dists / word_dists.sum(dim=1, keepdim=True)\n",
    "\n",
    "        total_count = 100\n",
    "        pyro.sample(\n",
    "            \"doc_words\",\n",
    "            dist.Multinomial(total_count=total_count, probs=word_dists),\n",
    "            obs=data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35277ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set up SVI ---\n",
    "guide = AutoDelta(lda_model)\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "svi = SVI(lda_model, guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9c7e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 0] loss = -629626.97\n",
      "[step 10] loss = -635384.84\n",
      "[step 20] loss = -640848.38\n",
      "[step 30] loss = -646002.81\n",
      "[step 40] loss = -650868.97\n",
      "[step 50] loss = -655508.97\n",
      "[step 60] loss = -660030.34\n",
      "[step 70] loss = -664584.53\n",
      "[step 80] loss = -669337.34\n",
      "[step 90] loss = -674356.12\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop ---\n",
    "num_steps = 100\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(X_tensor)\n",
    "    if step % 10 == 0:\n",
    "        print(f\"[step {step}] loss = {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0caccb0",
   "metadata": {},
   "source": [
    "Il tuo training è assolutamente in linea con le aspettative. Il loss parte da -645k perché stai modellando tanti documenti e parole contemporaneamente, e Pyro somma tutto.\n",
    "\n",
    "Fammi sapere se vuoi normalizzare, loggare o tracciare il progresso del training visivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract results ---\n",
    "posterior = guide()\n",
    "topic_words = posterior[\"topic_words\"]\n",
    "doc_topics = posterior[\"doc_topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ecb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIONAL: Save topic vectors per doc ---\n",
    "topic_df = pd.DataFrame(\n",
    "    doc_topics.detach().numpy(), columns=[f\"topic_{i}\" for i in range(K)]\n",
    ")\n",
    "df_with_topics = pd.concat([df.reset_index(drop=True), topic_df], axis=1)\n",
    "df_with_topics.to_csv(\"lda_output_with_topics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": 