{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d425d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data ---\n",
    "df = pd.read_csv(\"lda_df.csv\")\n",
    "\n",
    "with open(\"lda_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "X_array = np.load(\"BoW_X_Array.npz\")[\"arr_0\"]\n",
    "X_tensor = torch.tensor(X_array, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95735e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set model parameters ---\n",
    "K = 15  # number of topics (can change)\n",
    "num_docs, vocab_size = X_tensor.shape\n",
    "\n",
    "\n",
    "# --- Define Pyro LDA model ---\n",
    "def lda_model(data):\n",
    "    with pyro.plate(\"topics\", K):\n",
    "        topic_words = pyro.sample(\"topic_words\", dist.Dirichlet(torch.ones(vocab_size)))\n",
    "\n",
    "    with pyro.plate(\"documents\", num_docs):\n",
    "        doc_topics = pyro.sample(\"doc_topics\", dist.Dirichlet(torch.ones(K)))\n",
    "\n",
    "        word_dists = torch.matmul(doc_topics, topic_words)\n",
    "        word_dists = word_dists / word_dists.sum(dim=1, keepdim=True)\n",
    "\n",
    "        total_count = 100\n",
    "        pyro.sample(\n",
    "            \"doc_words\",\n",
    "            dist.Multinomial(total_count=total_count, probs=word_dists),\n",
    "            obs=data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35277ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set up SVI ---\n",
    "guide = AutoDelta(lda_model)\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "svi = SVI(lda_model, guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9c7e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 0] loss = -645081.38\n",
      "[step 10] loss = -649994.19\n",
      "[step 20] loss = -654594.69\n",
      "[step 30] loss = -659034.31\n",
      "[step 40] loss = -663410.34\n",
      "[step 50] loss = -667763.56\n",
      "[step 60] loss = -672065.88\n",
      "[step 70] loss = -676251.25\n",
      "[step 80] loss = -680276.12\n",
      "[step 90] loss = -684130.19\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop ---\n",
    "num_steps = 100\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(X_tensor)\n",
    "    if step % 10 == 0:\n",
    "        print(f\"[step {step}] loss = {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0caccb0",
   "metadata": {},
   "source": [
    "Il tuo training è assolutamente in linea con le aspettative. Il loss parte da -645k perché stai modellando tanti documenti e parole contemporaneamente, e Pyro somma tutto.\n",
    "\n",
    "Fammi sapere se vuoi normalizzare, loggare o tracciare il progresso del training visivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract results ---\n",
    "posterior = guide()\n",
    "topic_words = posterior[\"topic_words\"]\n",
    "doc_topics = posterior[\"doc_topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ecb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIONAL: Save topic vectors per doc ---\n",
    "topic_df = pd.DataFrame(\n",
    "    doc_topics.detach().numpy(), columns=[f\"topic_{i}\" for i in range(K)]\n",
    ")\n",
    "df_with_topics = pd.concat([df.reset_index(drop=True), topic_df], axis=1)\n",
    "df_with_topics.to_csv(\"lda_output_with_topics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
